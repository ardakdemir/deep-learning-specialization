{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6326b42c",
   "metadata": {},
   "source": [
    "# Introduction to ML Strategy\n",
    "(module-level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46c303",
   "metadata": {},
   "source": [
    "## Part 1. Why ML Strategy\n",
    "(video-level)\n",
    "\n",
    "\n",
    "Much more quickly and efficiently get your models working.\n",
    "\n",
    "\n",
    "Motivating example: Imagine you want to increase 90% accuracy of your cat classifier.\n",
    "\n",
    "You might have many ideas:\n",
    "- more data\n",
    "- more diverse set\n",
    "- training algorithm\n",
    "- ...\n",
    "\n",
    "\n",
    "There are sooo many things to try out. Only to realize for example more data barely changes the results. We need quick and effective ways to identify what ideas worth pursuing given a problem.\n",
    "\n",
    "This course teaches strategies and lessons learned for shipping large number of products: So stuff not really thought at school.\n",
    "\n",
    "- DL strategies are different than traditional ML strategies and constantly evolving!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91b95a",
   "metadata": {},
   "source": [
    "## Part 2. Orthogonalization\n",
    "\n",
    "One major challenge is sooo many things to try. \n",
    "\n",
    "Good ML engineers are very good at knowing what to change in order to get a desired change in the model performance.\n",
    "\n",
    "TV example:\n",
    "- Various knobs controlling various adjustments\n",
    "- Each knob has a distinct feature adjustment: vertical adjustment, horizontal adjustment, width etc.\n",
    "- Imagine that knobs change many things at once. \n",
    "- Orthogonalization: Each knob adjusts an distinct feature.\n",
    "\n",
    "\n",
    "Car example:\n",
    "- Steering \n",
    "- Accelerator\n",
    "- Braking\n",
    "Imagine these are controlled using same knob (e.g., 0.1 steering, 0.5 acceleration for a given button), it would be very hard to drive the car...\n",
    "\n",
    "You don't want your controllers to affect multiple things at once. In the car example, you dont want your accelerator change the direction of your car and vice-versa.\n",
    "\n",
    "\n",
    "Going back to ML: \n",
    "\n",
    "#### Chain of assumptions in ML \n",
    "In order of dependence you assume the following:\n",
    "\n",
    "- Fit training set well on cost function\n",
    "- (prior step assumes it helps) Fit dev set well on cost function\n",
    "- (which helps) Fit test set well on cost function\n",
    "- (which helps) Performs well in real world\n",
    "\n",
    "\n",
    "\n",
    "For each step, we need orthogonal (separate) set of things to try to achieve what you want.\n",
    "\n",
    "\n",
    "For example, if you are not achieving step 1 you try:\n",
    "\n",
    "- Bigger network\n",
    "- Adam optimization etc.\n",
    "\n",
    "But for step 2 you would try:\n",
    "\n",
    "- Regularization\n",
    "- Bigger training set\n",
    "\n",
    "For test set you would try:\n",
    "\n",
    "-  Get larger dev set: You over-tuned on the dev set\n",
    "\n",
    "For step 4 (doesn't perform well on real world):\n",
    "\n",
    "- Change dev/test set distribution\n",
    "- Change cost function: If your model performs well on test set it means something was wrong with the definition of your cost function..\n",
    "\n",
    "\n",
    "Andrew personally doesn't like Early stopping because it affects the first two steps at the same time (step1 and step2)... But of course it is not too horrible to sometimes have knobs that affect two things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bb0aa",
   "metadata": {},
   "source": [
    "# Setting up Your Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b152d",
   "metadata": {},
   "source": [
    "## Part 1. Single Number Evaluation Metric\n",
    "\n",
    "You will find that if you have one single number it will be much much faster to iterate!!\n",
    "\n",
    "Scenario one: \n",
    "\n",
    "    precision-recall. If one improves the other degrades. Which motivates us to use F-1 score instead so that we can iterate quicker.. Simple but always good to keep in mind. \n",
    "\n",
    "\n",
    "Scenario two: \n",
    "\n",
    "    Imagine you evaluate on four countries:\n",
    "\n",
    "```\n",
    "# error\n",
    "model1 = us: 3%, china: 7%, india: 5%, other: 5% \n",
    "model2 = us: 5%, china: 6%, india: 3%, other: 10% \n",
    "\n",
    "```\n",
    "\n",
    "It is better to look at average or weighted average so that you can effectively iterate over different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12527f0",
   "metadata": {},
   "source": [
    "## Part 2. Satisficing and Optimizing Metric\n",
    "\n",
    "It is not really meaningful to combine metrics always though (as was the case with accuracy or precision-recall).\n",
    "\n",
    "Example 1: Accuracy and Running time: It doesn't make really sense that you combine these metrics to come up with a single evaluation metric.\n",
    "    \n",
    "    Solution: Satificing/Optimizing metrics: You choose accuracy as the accuracy metric subject to the running time < 100ms (satisficing metric)\n",
    "    \n",
    "    \n",
    "Example 2: Wake word detection accuracy. Accuracy of Alexa detecting the word \"Alexa\"\n",
    "\n",
    "    Solution: Optimizing metric is accuracy. However we want to make sure we minimize the false positives. So we can set a satisificing metric: <2 false positives every 24 hours of operation.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662279d",
   "metadata": {},
   "source": [
    "## Part 3. Train/Dev/Test Set Distributions\n",
    "\n",
    "Example 1: Lets say you have dev/test set coming from various regions: \n",
    "\n",
    "    - US\n",
    "    - Other Europe\n",
    "    - Other Asia\n",
    "    - UK\n",
    "    - China\n",
    "    - India\n",
    "    - Australia\n",
    "    \n",
    "One way would be to set first 4 regions as dev and remaining three regions as test set. But this is actually a horrible idea because you will be iterating on a dev set that has different distribution on the data that you want to perform well on (that is what Test set stands for). \n",
    "\n",
    "    Solution: Randomly shuffle all data from all regions and split equally. This will ensure that your data for dev and test has same distribution.\n",
    "\n",
    "\n",
    "Real Scenario 1: Optimizing on dev set on loan approvals for medium income zip codes. Then, test set is on low income zip codes.\n",
    "\n",
    "    This is a typical problem, where the data you want to perform well on (test set) has different distribution than the data you iterated on... \n",
    "    \n",
    "To avoid this, we have to make sure:\n",
    "\n",
    "- Test should be representative of what you want to apply this model to and consider important to do well on.\n",
    "- Then make sure your dev set is also coming from the same distribution!!\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63cbdb",
   "metadata": {},
   "source": [
    "## Part 4. Size of the Dev and Test Sets\n",
    "\n",
    "How large should they be? It is changing in the deep learning era (as was discussed before).\n",
    "\n",
    "In early era it was just like 70-30% split or 60-20-20% split.\n",
    "\n",
    "\n",
    "Now we work with super large datasets. Reasonable to have 98-1-1% split instead. \n",
    "\n",
    "\n",
    "\n",
    "**Size of your test set**: Big enough that you get high confidence in the overall performance of your system. Imagine if you set it to be 100, it might be misleading in both ways.\n",
    "\n",
    "\n",
    "In some applications, you don't need train/dev/test split. You just need train/dev (this was also formerly discussed). This is unusual but sometimes it is fine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00b62c",
   "metadata": {},
   "source": [
    "## Part 5. When to Change Dev/Test Sets and Metrics?\n",
    "\n",
    "Sometimes part way through the project we might need to move the target and update the splits and metrics, how to do that ?\n",
    "\n",
    "\n",
    "When you think the rank order from your metric+dev: Prefer A whereas company user: Prefer B.\n",
    "\n",
    "\n",
    "**Example: cat and non-violent example**\n",
    "\n",
    "Cat classifier with lower error misclassifies a lot of violent images. This is a situation where the dev set and your evaluation metric (accuracy) is not aligned with user preference. User and company absolutely avoid violent image.\n",
    "\n",
    "Solution:\n",
    "\n",
    "    Instead of using averaged error on all samples, have a weighted average of your predictions:\n",
    "    \n",
    "$$\n",
    "Error = \\dfrac{1}{\\sum_i w_i} \\sum_i w^{(i)} L\\{y_{pred},y\\}\\\\\n",
    "w^{(i)} = 1 \\text{ if } x^{(i)} \\text{ is non-violent else } 10\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This is actually an example of orthogonalization (separation of concerns):\n",
    "\n",
    "1- Focus on how to define a metric to evaluate the classifiers (setting the target).\n",
    "\n",
    "2- Then, worry separately about how to do well on this metric (training the model to hit the target).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961dbcd",
   "metadata": {},
   "source": [
    "# Comparing to Human-level Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d9d6b",
   "metadata": {},
   "source": [
    "## Part 1. Why human-level Performance?\n",
    "\n",
    "Recently there is big trend of comparing ML models to humans.\n",
    "\n",
    "Usually, performance is very high until reaching human-level. After surpass human level, the improvement usually slows down significantly and converges to an upper theoretical error which is called: Bayes optimal error. This is the theoretical upper bound, it is basically impossible to get anything above this performance.\n",
    "\n",
    "Bayes optimal error doesn't have to be full score (e.g. 100% accuracy) all the time. If the images are very blurry we might have bayes optimal cat classifier of less than 100% accuracy.\n",
    "\n",
    "\n",
    "Why progress slows down after human-level?\n",
    "\n",
    "Two main reasons:\n",
    "- Human level is usually close to bayes optimal.\n",
    "- If below human-level, there are many tools we can use to improve the models performance.\n",
    "\n",
    "\n",
    "Some example tools as long as human>ML model in performance:\n",
    "\n",
    "- Get labeled data from humans.\n",
    "- Manual error analysis: Gain insight: why a person get it right and model fail.\n",
    "- Better analysis of bias/variance. As long as humans are performing better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12fa9d",
   "metadata": {},
   "source": [
    "## Part 2. Avoidable Bias\n",
    "\n",
    "We usually want to do \"Well\" on the training set. But having a human-level benchmark will prevent us from doing \"too well\" on the training set (aka overfitting) and also prevent us from trying to improve training perf. after certain point and focus on other aspects.\n",
    "\n",
    "Let's think human error 1% on a task. if training error is 8% and 10% dev error. You would focus on bias.\n",
    "\n",
    "    So if your model is far from human-level on training set it can be considered as \"avoidable bias\"!\n",
    "\n",
    "Let's think human error 7.5% on a task. if training error is 8% and 10% on dev. Then you might not focus on bias and you would focus on reducing variance instead!!\n",
    "\n",
    "Human-level error is a nice proxy for Bayes error for most tasks such as object detection!\n",
    "\n",
    "    So if your model is close to human-level on training set, the remaining bias can be considered as \"unavoidable bias\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59018a07",
   "metadata": {},
   "source": [
    "## Part 3. Understanding Human-level Performance\n",
    "\n",
    "Is it \"random human\", \"expert human\", \"team of experts\"? \n",
    "\n",
    "\n",
    "Medical image classification:\n",
    "\n",
    "- Typical human: 3%\n",
    "- Typical doctor: 1%\n",
    "- Experienced doctor: 0.7% \n",
    "- Team of experienced 0.5% error\n",
    "\n",
    "Considering that human-level is used as proxy to \"Bayes optimal\" error, Andrew suggests using 0.5% as the \"human-level\" error because last option proves that such accuracy is possible.\n",
    "\n",
    "\n",
    "For deploying a system or a publication, it depends on your context. If your surpassed typical doctor level, you might still want to deploy this model or publish your result.\n",
    "\n",
    "\n",
    "As long as your avoidable bias (diff between human and model on training) is larger than your variance (model on training vs model on dev), you should focus on bias and vice-versa.\n",
    "\n",
    "\n",
    "As models perform better and get close to human level, it becomes more critical that we set the correct \"bayes\" error to figure out which one (bias or variance) we should focus on next.\n",
    "\n",
    "\n",
    "Remember that don't just set bias as diff from 0% error. Instead, use human-level as proxy to bayes error whenever possible..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01de29e",
   "metadata": {},
   "source": [
    "## Part 4. Surpassing Human-level Performance\n",
    "\n",
    "- Team of humans: 0.5%\n",
    "- One human: 1%\n",
    "- Training error: 0.6%\n",
    "- Dev error : 0.8%\n",
    "\n",
    "So your avoidable bias is 0.1% and 0.2% is your variance.\n",
    "\n",
    "\n",
    "Example 2: \n",
    "\n",
    "\n",
    "- Team of humans: 0.5%\n",
    "- One human: 1%\n",
    "- Training error: 0.3%\n",
    "- Dev error : 0.4%\n",
    "\n",
    "Now it is more difficult whether we should focus on bias or variance because we are already better than team of humans. We are not sure whether we can further reduce the bias..\n",
    "\n",
    "\n",
    "Examples ML surpass human-level:\n",
    "\n",
    "- Online advertising\n",
    "- Product recommendations\n",
    "- Logistics (predicting transit time)\n",
    "- Loan approvals\n",
    "\n",
    "All four examples have the following characteristics:\n",
    "\n",
    "- learning from structured data. \n",
    "- Not natural perception problems such as vision (which humans are good at). \n",
    "- Also lot more data than a human can look at.\n",
    "\n",
    "\n",
    "Besides there are some speech recognition, image recognition, narrow radiology for which ML can surpass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab4dda",
   "metadata": {},
   "source": [
    "## Part 5. Improving your Model Performance\n",
    "\n",
    "Guidelines bringing everything together.\n",
    "\n",
    "Two fundamental assumptions:\n",
    "\n",
    "- You can fit the training set pretty well-> avoidable bias\n",
    "- The training set performance generalizes well on dev/test -> variance\n",
    "\n",
    "\n",
    "Reducing (avoidable) bias and variance:\n",
    "\n",
    "Avoidable bias:\n",
    "\n",
    "- Train bigger model\n",
    "- Train longer/better optimization algorithms\n",
    "- NN architecture/hyperparam search\n",
    "\n",
    "\n",
    "Variance:\n",
    "\n",
    "- More training data \n",
    "- Regularization: l2, dropout, data augmentation\n",
    "- NN architecture/hyperparam search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057353e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe561b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e87ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc0c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f396e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae10a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2078d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea4602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2afab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22b187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266082df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82327b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d519ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929727b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee974ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1bbda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc83f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8904bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-karpathy",
   "language": "python",
   "name": "venv-karpathy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
