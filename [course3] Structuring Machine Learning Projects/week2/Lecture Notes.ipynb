{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1792da",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042005ee",
   "metadata": {},
   "source": [
    "## Part 1. Carrying out Error Analysis\n",
    "\n",
    "If perf is lower than human-level you can carry out error analysis to figure out the issues.\n",
    "\n",
    "\n",
    "Example: Cat classifier fails on certain dog pictures.\n",
    "\n",
    "Opp sizing: If you want to add a lot of dog picture labeling, do the following:\n",
    "\n",
    "- Get ~100 mislabeled dev set examples.\n",
    "- Count up how many are dogs.\n",
    "\n",
    "So if only 5% were dogs than the opp size of the dog annotation will only bring 10% to 9.5% which might not be very impactful. \n",
    "\n",
    "Such approach gives you \"ceiling\" about the opp size.\n",
    "\n",
    "\n",
    "If you see 50 of them were dogs, than your error might go all the way down to 5%!! \n",
    "\n",
    "\n",
    "If you are building applied systems, it is very valuable to do such manual work and have some manual improvements, it is totally fine to do it!!\n",
    "\n",
    "\n",
    "**Evaluate multiple ideas in parallel**\n",
    "\n",
    "Have a spreadsheet where each row is task sample and each column is one idea:\n",
    "\n",
    "- Fix pictures of dogs\n",
    "- Fix great cats (lions,panthers) being misrecognized\n",
    "- Blurry images \n",
    "- ...\n",
    "\n",
    "\n",
    "So while going over each sample simply annotate which categories this error belong to (sometimes multiple categories: blurry dog image, rainy dog image for example).\n",
    "\n",
    "\n",
    "Then based on this analysis, you have better idea on what to improve in the next iteration. If you have multiple big opportunities, you can even have multiple teams in parallel: one fix dog issue, the other fix blurry image issue (this reminded me of how Siri team worked on many initiatives before the launch try to bring the error rate down)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bf131",
   "metadata": {},
   "source": [
    "## Part 2. Cleaning up Incorrectly labeled data\n",
    "\n",
    "Is it worthwhile to take a lot of effort to fix incorrectly labeled data?\n",
    "\n",
    "\n",
    "Random errors: Annotators made some random mistakes.\n",
    "\n",
    "\n",
    "Systematic errors: Annotators always labeled \"white dogs\" as cats. \n",
    "\n",
    "Training set: DL algorithms are quite robust to _random_ errors in the training set. It is very common that some famous models are trained on datasets that had some incorrectly labeled BUT systematic errors would cause issues!\n",
    "\n",
    "**How about dev/test?** \n",
    "\n",
    "- Add an \"incorrectly labeled?\" column in your error analysis to estimate the % of occurrence for these. \n",
    "    \n",
    "- If let's say only 6% of 10% error (0.6%) is coming from incorret labels it might not worth the effort. Focus on the remaining 9.4% \n",
    "\n",
    "- Suppose your overall error went down to 2%. Now your incorrect labels account for 30% of your overall error. Now might be better time to fix the labeling issues.\n",
    "\n",
    "Some guidelines around this:\n",
    "\n",
    "- Apply same process to your dev and test sets to ensure they still have the same distribution.\n",
    "- Consider examining examples your algorithm got RIGHT as well. If you only fix the samples it got wrong, it gives your algorithm a bit of unfair advantage. This is not super easy because if the model has 98% accuracy, it would take a looot to validate the correctly predicted samples.\n",
    "- Remember that train and dev/test data may now come from slightly different distributions (welcome to data mismatch issues). Your training is kinda robust so it could be fine.\n",
    "\n",
    "\n",
    "**Some other wisdom**:\n",
    "\n",
    "- In DL era, there is this tendency to simply train the model and get the aggregated results and assume you are done if performance is satisfactory.\n",
    "- However, in applied deep learning there is always hand engineering and manual error analysis (then DL practitioners would like to acknowledge).\n",
    "- Some people have hesitancy to look into manual error analysis, read data (which is less exciting than coding etc.). But this is actually super important: Put some hours and look into error analysis manually to understand the next steps. This is critical and Andrew still does it in his projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8ac1b",
   "metadata": {},
   "source": [
    "## Part 3. Build your first system quickly, then iterate\n",
    "\n",
    "Speech Recognition example. There are maaany things to do to reduce the noise and improve accuracy:\n",
    "\n",
    "- Stuttering\n",
    "- Noisy background\n",
    "- Accented speech\n",
    "- Far from microphone\n",
    "\n",
    "\n",
    "For any ML application, there could be 50 different directions, which one to prioritize for your specific use case?\n",
    "\n",
    "Solution: Set up dev/test set and metric, build initial system quickly, use bias/variance analysis + error analysis to prioritize next steps.\n",
    "\n",
    "So important guideline: Build your first system quickly, then iterate!!! Do not overcomplicate your initial solution. Build something quick and iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b822c1f",
   "metadata": {},
   "source": [
    "# Mismatched Training and Dev/Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc493733",
   "metadata": {},
   "source": [
    "# Part 1. Training and Testing on Different Distributions\n",
    "\n",
    "DL models have a lot of hunger for MORE data. Some teams might put some data that is not from same distribution with dev/test to increase their training set size.\n",
    "\n",
    "Examples\n",
    "\n",
    "- Data from webpages: 200k\n",
    "- Data from mobile app: 10k (dev/test set)\n",
    "\n",
    "On the internet you might have huge amount of data but you might have little data from mobile app (which you ultimately care about).\n",
    "\n",
    "So what can you do?\n",
    "\n",
    "\n",
    "(bad option) Option 1: Random shuffling\n",
    "\n",
    "- Combine both dataset, randomly shuffle them and split to train/dev/test. So your training will be mostly internet but also have few mobile app data.\n",
    "- Main disadvantage is there will be minimal mobile app samples on dev and test.\n",
    "- Like only 238 example on dev test will be actually coming from the mobile app pictures....\n",
    "\n",
    "\n",
    "(good option) Option 2:\n",
    "- Training set have all web (200k) + 5k from mobile app\n",
    "- Test: 2.5k mobile app\n",
    "- Dev: 2.5k mobile app\n",
    "- This way we only evaluate our model only on relevant data!!\n",
    "- Main disadvantage is that your training is coming from different distribution than your dev/test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b6e37",
   "metadata": {},
   "source": [
    "## Part 2. Bias and Variance with Mismatched Data Distributions \n",
    "\n",
    "The way you analyze bias and variance changes when your training and dev/test is coming from DIFFERENT distribution.\n",
    "\n",
    "Assume humans get 0% error and train and dev are from different distribution. \n",
    "\n",
    "- Training error 1%.\n",
    "- Dev error 10%.\n",
    "- In the above case we are not sure if this is a variance issue because it might be that the training data was easier (contained more easy examples). We changed two things at once:\n",
    "    - The algorithm saw the training but not dev.\n",
    "    - The distribution of training and dev are different.\n",
    "    \n",
    "We don't know which of the above two things caused the issue.\n",
    "\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "Create a new set: Training-dev set which has same distribution as training set but NOT used for training. Critical thing here is that it is coming from the same distribution AND that it was not seen during training.\n",
    "\n",
    "Now if we see train error 1%, train-dev error is 9% and dev error is 10%, this definitely shows that this is a variance issue. Because train-dev is coming from the same distribution.\n",
    "\n",
    "\n",
    "If we had train error 1%, train-dev 1.5% and dev 10%, this is a data mismatch problem and requires different solution. \n",
    "\n",
    "\n",
    "\n",
    "**General principles** \n",
    "\n",
    "Main things to look at:\n",
    "\n",
    "- Human level (bayes) error\n",
    "- Training set error\n",
    "- Train-dev error\n",
    "- Dev error\n",
    "- Test error\n",
    "\n",
    "These are enough to determine all below:\n",
    "- Avoidable bias\n",
    "- Variance\n",
    "- Data Mismatch\n",
    "- Degree of overfitting to the dev set\n",
    "\n",
    "\n",
    "Note: If you overfit to dev set, might be good idea to increase the dev set size.\n",
    "\n",
    "\n",
    "Sometimes we would see that train error % is actually HIGHER than dev error. It could be the case that training data is actually harder to classify than your downstream task (which dev/test is coming from).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3b13a",
   "metadata": {},
   "source": [
    "## Part 3. Addressing Data Mismatch\n",
    "\n",
    "(Honestly there are no super systematic ways to deal with data mismatch problem)\n",
    "\n",
    "\n",
    "- Carry out manual error analysis to understand difference between training and dev/test (don't do error analysis on test of course).\n",
    "\n",
    "For example you can see that dev contains many examples with car noise compared to training\n",
    "\n",
    "- See if you can make the training data more similar or collect more data similar to dev/test.\n",
    "\n",
    "**Synthetic Data**\n",
    "\n",
    "One way you can achieve this is to use synthetic data. Get normal sentence and car noise simply add them together to get synthesized in-car audio... \n",
    "\n",
    "\n",
    "Some nuance about synthetic data generation:\n",
    "\n",
    "- Imagine you have 10k hours of human text audio (someone reading anormal sentence).\n",
    "- 1 hour of car noise \n",
    "- If you simply multiply the car noise 10k times for all human text, your model might actually overfit to the 1 hour car noise.\n",
    "- And the 1 hour car noise might only be a small portion of all possible in-car noise.\n",
    "\n",
    "\n",
    "Challenges:\n",
    "\n",
    "- It would be difficult to detect differences for the different in-car noises for the human ear...\n",
    "- Your synthetic data might only represent a small set of all possible cases.\n",
    "\n",
    "\n",
    "**Example: Car detection**\n",
    "\n",
    "\n",
    "If we use synthetically generated car images, it might be the case that these artificial images might represent only a tiny portion of all car representations. For humans, we think they are all different cars but from model perspective they might not be representative of all cars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ff918",
   "metadata": {},
   "source": [
    "# Learn from Multiple Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707b137",
   "metadata": {},
   "source": [
    "## Part 1. Transfer Learning\n",
    "\n",
    "Use cat classifier model to radiology diagnosis.\n",
    "\n",
    "- Remove the last layer of your classifier.\n",
    "- Add new last layer. Train the last layer of your model on the radiology diagnosis dataset.\n",
    "\n",
    "Sometimes, you might want to freeze all hidden layers (for example if your new data is limited in size). If you have a looot of data on the new data you might train the whole model.\n",
    "\n",
    "It is useful because low level features are transferrable across tasks.\n",
    "\n",
    "Sometimes you might also want to add multiple layers for the new task...\n",
    "\n",
    "\n",
    "\n",
    "When does transfer learning make sense?\n",
    "\n",
    "- When the source task has a lot of data.\n",
    "- Target task data is limited.\n",
    "- Input is same (both audio, image etc.).\n",
    "- Low level features from A could be helpful for learning B (this is kind of human assumption).\n",
    "\n",
    "If you had the opposite case (radiology 100k data and cat classifier has 100 samples) it doesnt make sense to transfer from the cat classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1b9a7",
   "metadata": {},
   "source": [
    "## Part 2. Multi-task Learning\n",
    "\n",
    "Learn from multiple tasks at the same time!! Transfer learning was sequential, this is simultaneous.\n",
    "\n",
    "\n",
    "Typical example is autonomous driving. You have so many tasks:\n",
    "\n",
    "- Pedestrian detection\n",
    "- Car detection\n",
    "- Stop signs\n",
    "- Traffic lights\n",
    "- ...\n",
    "\n",
    "Some image will have multiple of these so the label (y) might look like this: $[0,1,1,0]$ this is multi-hot encoding.\n",
    "\n",
    "Model for predicting all at once:\n",
    "\n",
    "$$\n",
    "Cost = \\dfrac{1}{m} \\sum_i^{m} \\sum_j^{4} Loss(y_{predj}, y_j)\n",
    "$$\n",
    "\n",
    "- Sum the loss over 4 components.\n",
    "\n",
    "- Main difference from the softmax loss is that we dont have single label for each sample. So the probabilities of this (4,1) vector shouldn't sum up to 1!!\n",
    "\n",
    "- Such model is a multi-task learning model because these could be 4 separate models. \n",
    "\n",
    "\n",
    "**Interesting Note.**\n",
    "\n",
    "- Multi-task learning would stil work even if you have some missing labels. \n",
    "- Assume you have some annotation for car and pedestrian only (some annotators did not have the other two classes.) and others had first two missing.\n",
    "    - Example annotation : $[1,0,?,?]$ (pedestrian, no car and missing annotation for last two) or $[?,?,1,1]$.\n",
    "- You can use this data for multi-task learning even though all samples have missing annotation.\n",
    "- Only thing you change is you remove calculating loss over $j$ if $y_j$ (annotation for that class) is missing\n",
    "\n",
    "\n",
    "\n",
    "#### When multi-task learning makes sense?\n",
    "\n",
    "- Low level features are shared across the tasks.\n",
    "- Usually amount of data you have for each task is quite similar.\n",
    "- If you have 100 tasks with 1k samples each, by training on all tasks you get the 1k samples from the other 99 tasks which gives you 100x increase!!\n",
    "- Can train a big enough neural network that can do well on all the tasks. Probably it will take longer and your model needs to be larger.\n",
    "\n",
    "It is used muuuch less often than sequential transfer learning. Computer vision is one of main application (object detection of all object types).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac6c84",
   "metadata": {},
   "source": [
    "# End-to-end Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a31ed",
   "metadata": {},
   "source": [
    "## Part 1. What is e2e deep learning?\n",
    "\n",
    "Multiple stages of machine learning -> Only one DNN to handle everything\n",
    "\n",
    "\n",
    "\n",
    "Traditional Speech Recognition\n",
    "\n",
    "- Convert audio to some low-level features (using MFCC)\n",
    "- ML model to extract phonemes\n",
    "- Another tool to get words\n",
    "- Finally get the transcript as the prediction (Y)\n",
    "\n",
    "\n",
    "E2E approach\n",
    "\n",
    "- Raw audio to transcript (Y)\n",
    "\n",
    "Traditional approach makes sense when we lack data. With a lot of raw data, E2E approach might be more suitable.\n",
    "\n",
    "\n",
    "\n",
    "**Example 2.** Face Recognition\n",
    "\n",
    "Best approach is actually a multi-step approach.\n",
    "\n",
    "- Raw image -> Face detection model extract the face only\n",
    "- Face -> Identity model (only gets input the camera image)\n",
    "\n",
    "Makes sense because one-step approach would be very complicated and sparse data for all camera angles etc.\n",
    "\n",
    "\n",
    "- Each task has a lot of data available\n",
    "- Each task is relatively easy\n",
    "\n",
    "\n",
    "In contrast, \n",
    "\n",
    "- Very limited that combines the both (combination)\n",
    "- Much harder to get identity from far away camera shot.\n",
    "\n",
    "\n",
    "\n",
    "**Example 3.** Machine Translation\n",
    "\n",
    "- We have a lot of pairs of texts (English-> French)\n",
    "- For this task, E2E makes sense and performs well!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6eac94",
   "metadata": {},
   "source": [
    "## Part 2. Whether to use E2E Learning\n",
    "\n",
    "Pros: \n",
    "\n",
    "- Let the data speak. Pure ML approach might be able to capture stuff that outperform the human defined concepts. E.g., forcing models to learn phonemes is restrictive\n",
    "- Less hand-designing of components needed \n",
    "\n",
    "\n",
    "Cons: \n",
    "\n",
    "- May need large data.. \n",
    "- Potentially useful hand-designed insights are excluded..\n",
    "\n",
    "\n",
    "When you have ton of data, hand-designed knowledge is less critical. For some tasks, such hand-designed features might be actually super helpful.\n",
    "\n",
    "\n",
    "So key question: do you have sufficient data to learn a function of the complexity needed to map X->Y? \n",
    "\n",
    "Here sufficient and complexity are hard to define in a mathematical way of course.\n",
    "\n",
    "\n",
    "Andrew finished with illustrating that autonomous driving consists of many distinct tasks:\n",
    "\n",
    "- Object detection\n",
    "- Route planning \n",
    "- Steering\n",
    "\n",
    "\n",
    "Each step is a different system, e.g., route planning is a software it is not a machine learning model. Likewise steering is also simply a software.\n",
    "\n",
    "\n",
    "Sometimes E2E is exciting but doesn't really make sense in some practical applications.\n",
    "\n",
    "Given input image -> DNN outputs the steering function hehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467260b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c83de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84489a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab176f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fedd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918ea00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415a5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6824dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60473a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5545f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a875eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c6dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96322d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07065c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aadb424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2626299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241dee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf64b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-karpathy",
   "language": "python",
   "name": "venv-karpathy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
