{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5f955f",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7321b",
   "metadata": {},
   "source": [
    "## Part 1. Carrying out Error Analysis\n",
    "\n",
    "If perf is lower than human-level you can carry out error analysis to figure out the issues.\n",
    "\n",
    "\n",
    "Example: Cat classifier fails on certain dog pictures.\n",
    "\n",
    "Opp sizing: If you want to add a lot of dog picture labeling, do the following:\n",
    "\n",
    "- Get ~100 mislabeled dev set examples.\n",
    "- Count up how many are dogs.\n",
    "\n",
    "So if only 5% were dogs than the opp size of the dog annotation will only bring 10% to 9.5% which might not be very impactful. \n",
    "\n",
    "Such approach gives you \"ceiling\" about the opp size.\n",
    "\n",
    "\n",
    "If you see 50 of them were dogs, than your error might go all the way down to 5%!! \n",
    "\n",
    "\n",
    "If you are building applied systems, it is very valuable to do such manual work and have some manual improvements, it is totally fine to do it!!\n",
    "\n",
    "\n",
    "**Evaluate multiple ideas in parallel**\n",
    "\n",
    "Have a spreadsheet where each row is task sample and each column is one idea:\n",
    "\n",
    "- Fix pictures of dogs\n",
    "- Fix great cats (lions,panthers) being misrecognized\n",
    "- Blurry images \n",
    "- ...\n",
    "\n",
    "\n",
    "So while going over each sample simply annotate which categories this error belong to (sometimes multiple categories: blurry dog image, rainy dog image for example).\n",
    "\n",
    "\n",
    "Then based on this analysis, you have better idea on what to improve in the next iteration. If you have multiple big opportunities, you can even have multiple teams in parallel: one fix dog issue, the other fix blurry image issue (this reminded me of how Siri team worked on many initiatives before the launch try to bring the error rate down)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0ed5",
   "metadata": {},
   "source": [
    "## Part 2. Cleaning up Incorrectly labeled data\n",
    "\n",
    "Is it worthwhile to take a lot of effort to fix incorrectly labeled data?\n",
    "\n",
    "\n",
    "Random errors: Annotators made some random mistakes.\n",
    "\n",
    "\n",
    "Systematic errors: Annotators always labeled \"white dogs\" as cats. \n",
    "\n",
    "Training set: DL algorithms are quite robust to _random_ errors in the training set. It is very common that some famous models are trained on datasets that had some incorrectly labeled BUT systematic errors would cause issues!\n",
    "\n",
    "**How about dev/test?** \n",
    "\n",
    "    Add an \"incorrectly labeled?\" column in your error analysis to estimate the % of occurrence for these. \n",
    "    \n",
    "If let's say only 6% of 10% error (0.6%) is coming from incorret labels it might not worth the effort. Focus on the remaining 9.4% \n",
    "\n",
    "\n",
    "Suppose your overall error went down to 2%. Now your incorrect labels account for 30% of your overall error. Now might be better time to fix the labeling issues.\n",
    "\n",
    "Some guidelines around this:\n",
    "\n",
    "- Apply same process to your dev and test sets to ensure they still have the same distribution.\n",
    "- Consider examining examples your algorithm got RIGHT as well. If you only fix the samples it got wrong, it gives your algorithm a bit of unfair advantage. This is not super easy because if the model has 98% accuracy, it would take a looot to validate the correctly predicted samples.\n",
    "- Remember that train and dev/test data may now come from slightly different distributions. Your training is kinda robust so it could be fine.\n",
    "\n",
    "\n",
    "**Some other wisdom**:\n",
    "\n",
    "- In DL era, there is this tendency to simply train the model and get the aggregated results and assume you are done if performance is satisfactory.\n",
    "- However, in applied deep learning there is always hand engineering and manual error analysis (then DL practitioners would like to acknowledge).\n",
    "- Some people have hesitancy to look into manual error analysis, read data (which is less exciting than coding etc.). But this is actually super important: Put some hours and look into error analysis manually to understand the next steps. This is critical and Andrew still does it in his projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6e255",
   "metadata": {},
   "source": [
    "## Part 3. Build your first system quickly, then iterate\n",
    "\n",
    "Speech Recognition example. There are maaany things to do to reduce the noise and improve accuracy:\n",
    "\n",
    "- Stuttering\n",
    "- Noisy background\n",
    "- Accented speech\n",
    "- Far from microphone\n",
    "\n",
    "\n",
    "For any ML application, there could be 50 different directions, which one to prioritize for your specific use case?\n",
    "\n",
    "Solution: Set up dev/test set and metric, build initial system quickly, use bias/variance analysis + error analysis to prioritize next steps.\n",
    "\n",
    "So important guideline: Build your first system quickly, then iterate!!! Do not overcomplicate your initial solution. Build something quick and iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e20e72",
   "metadata": {},
   "source": [
    "# Mismatched Training and Dev/Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f2036",
   "metadata": {},
   "source": [
    "# Part 1. Training and Testing on Different Distributions\n",
    "\n",
    "DL models have a lot of hunger for MORE data. Some teams might put some data that is not from same distribution with dev/test to increase their training set size.\n",
    "\n",
    "Examples\n",
    "\n",
    "- Data from webpages: 200k\n",
    "- Data from mobile app: 10k (dev/test set)\n",
    "\n",
    "On the internet you might have huge amount of data but you might have little data from mobile app (which you ultimately care about).\n",
    "\n",
    "So what can you do?\n",
    "\n",
    "\n",
    "(bad option) Option 1:\n",
    "\n",
    "- Combine both dataset, randomly shuffle them and split to train/dev/test. So your training will be mostly internet but also have few mobile app data.\n",
    "- Main disadvantage is there will be minimal mobile app samples on dev and test.\n",
    "- Like only 238 example on dev test will be actually coming from the mobile app pictures....\n",
    "\n",
    "\n",
    "(good option) Option 2:\n",
    "- Training set have all web (200k) + 5k from mobile app\n",
    "- Test: 2.5k mobile app\n",
    "- Dev: 2.5k mobile app\n",
    "- This way we only evaluate our model only on relevant data!!\n",
    "- Main disadvantage is that your training is coming from different distribution than your dev/test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf851dfd",
   "metadata": {},
   "source": [
    "## Part 2. Bias and Variance with Mismatched Data Distributions \n",
    "\n",
    "The way you analyze bias and variance changes when your training and dev/test is coming from DIFFERENT distribution.\n",
    "\n",
    "Assume humans get 0% error and train and dev are from different distribution. \n",
    "\n",
    "- Training error 1%.\n",
    "- Dev error 10%.\n",
    "- In the above case we are not sure if this is a variance issue because it might be that the training data was easier (contained more easy examples). We changed two things at once:\n",
    "    - The algorithm saw the training but not dev.\n",
    "    - The distribution of training and dev are different.\n",
    "    \n",
    "We don't know which of the above two things caused the issue.\n",
    "\n",
    "\n",
    "**Solution: **\n",
    "\n",
    "Create a new set: Training-dev set which has same distribution as training set but NOT used for training. Critical thing here is that it is coming from the same distribution AND that it was not seen during training.\n",
    "\n",
    "Now if we see train error 1%, train-dev error is 9% and dev error is 10%, this definitely shows that this is a variance issue. Because train-dev is coming from the same distribution.\n",
    "\n",
    "\n",
    "If we had train error 1%, train-dev 1.5% and dev 10%, this is a data mismatch problem and requires different solution. \n",
    "\n",
    "\n",
    "\n",
    "**General principles** \n",
    "\n",
    "Main things to look at:\n",
    "\n",
    "- Human level (bayes) error\n",
    "- Training set error\n",
    "- Train-dev error\n",
    "- Dev error\n",
    "- Test error\n",
    "\n",
    "These are enough to determine all below:\n",
    "- Avoidable bias\n",
    "- Variance\n",
    "- Data Mismatch\n",
    "- Degree of overfitting to the dev set\n",
    "\n",
    "\n",
    "Note: If you overfit to dev set, might be good idea to increase the dev set size.\n",
    "\n",
    "\n",
    "Sometimes we would see that train error % is actually HIGHER than dev error. It could be the case that training data is actually harder to classify than your downstream task (which dev/test is coming from).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deba200",
   "metadata": {},
   "source": [
    "## Part 3. Addressing Data Mismatch\n",
    "\n",
    "(Honestly there are no super systematic ways to deal with data mismatch problem)\n",
    "\n",
    "\n",
    "- Carry out manual error analysis to understand difference between training and dev/test (don't do error analysis on test of course).\n",
    "\n",
    "For example you can see that dev contains many examples with car noise compared to training\n",
    "\n",
    "- See if you can make the training data more similar or collect more data similar to dev/test.\n",
    "\n",
    "One way you can achieve this is to use synthetic data. Get normal sentence and car noise simply add them together to get synthesized in-car audio... \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd4485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5041c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42a667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2baaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36975ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed475129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6466ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fed388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53725432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a6387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f98576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f4934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a717ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7ff31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f73e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682377c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531bf6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-karpathy",
   "language": "python",
   "name": "venv-karpathy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
