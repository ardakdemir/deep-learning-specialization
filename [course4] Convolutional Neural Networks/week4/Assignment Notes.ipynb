{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71dabbe1",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494995f9",
   "metadata": {},
   "source": [
    "<a name='4-2-1'></a>\n",
    "#### 4.2.1 - Style Matrix\n",
    "\n",
    "#### Gram matrix\n",
    "* The style matrix is also called a \"Gram matrix.\" \n",
    "* In linear algebra, the Gram matrix G of a set of vectors $(v_{1},\\dots ,v_{n})$ is the matrix of dot products, whose entries are ${\\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j})  }$. \n",
    "* In other words, $G_{ij}$ compares how similar $v_i$ is to $v_j$: If they are highly similar, you would expect them to have a large dot product, and thus for $G_{ij}$ to be large. \n",
    "\n",
    "#### Two meanings of the variable $G$\n",
    "* Note that there is an unfortunate collision in the variable names used here. Following the common terminology used in the literature: \n",
    "    * $G$ is used to denote the Style matrix (or Gram matrix) \n",
    "    * $G$ also denotes the generated image. \n",
    "* For the sake of clarity, in this assignment $G_{gram}$ will be used to refer to the Gram matrix, and $G$ to denote the generated image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05236c1a",
   "metadata": {},
   "source": [
    "## Notes About the Style Matrix## \n",
    "\n",
    "Gram Matrix is not matrix x matrix multiplication over each pair of nh x nw channels!! There is a subtle difference here. Because we only multiply things that are in the same position on the original feature volumes. That is we don't multiple (0,0,1) (0,0 of channel 1) with (0,2,3) (0,2 of channel 3) which we would in a normal matrix multiplication step!!\n",
    "\n",
    "\n",
    "We call it Gram matrix because the Gram matrix is applied over the \"unrolled\" activation matrix which is 2D and of size: $(n_h \\cdot n_w , n_c)$\n",
    "\n",
    "$$\\mathbf{G}_{gram} = \\mathbf{A}_{unrolled} \\mathbf{A}_{unrolled}^T$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### $G_{(gram)ij}$: correlation\n",
    "The result is a matrix of dimension $(n_C,n_C)$ where $n_C$ is the number of filters (channels). The value $G_{(gram)i,j}$ measures how similar the activations of filter $i$ are to the activations of filter $j$. \n",
    "\n",
    "#### $G_{(gram),ii}$: prevalence of patterns or textures\n",
    "* The diagonal elements $G_{(gram)ii}$ measure how \"active\" a filter $i$ is. \n",
    "* For example, suppose filter $i$ is detecting vertical textures in the image. Then $G_{(gram)ii}$ measures how common  vertical textures are in the image as a whole.\n",
    "* If $G_{(gram)ii}$ is large, this means that the image has a lot of vertical texture. \n",
    "\n",
    "\n",
    "By capturing the prevalence of different types of features ($G_{(gram)ii}$), as well as how much different features occur together ($G_{(gram)ij}$), the Style matrix $G_{gram}$ measures the style of an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769eb1e",
   "metadata": {},
   "source": [
    "How do you choose the coefficients for each layer? The deeper layers capture higher-level concepts, and the features in the deeper layers are less localized in the image relative to each other. So if you want the generated image to softly follow the style image, try choosing larger weights for deeper layers and smaller weights for the first layers. In contrast, if you want the generated image to strongly follow the style image, try choosing smaller weights for deeper layers and larger weights for the first layers.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<font color = 'blue'>\n",
    "    \n",
    "**What you should remember:**\n",
    "    \n",
    "- The style of an image can be represented using the Gram matrix of a hidden layer's activations. \n",
    "- You get even better results by combining this representation from multiple different layers. \n",
    "- This is in contrast to the content representation, where usually using just a single hidden layer is sufficient.\n",
    "- Minimizing the style cost will cause the image $G$ to follow the style of the image $S$. \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583aae5",
   "metadata": {},
   "source": [
    "<a name='5-3'></a>\n",
    "\n",
    "!! Turns out that we don't actually completely randomly generate noise for the initial image!! It turns out that it looks exactly like the Content image with some randomly generated noise on top of it. This was my idea too!!\n",
    "\n",
    "\n",
    "### 5.3 Randomly Initialize the Image to be Generated\n",
    "Now, you get to initialize the \"generated\" image as a noisy image created from the content_image.\n",
    "\n",
    "* The generated image is slightly correlated with the content image.\n",
    "* By initializing the pixels of the generated image to be mostly noise but slightly correlated with the content image, this will help the content of the \"generated\" image more rapidly match the content of the \"content\" image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a46a7",
   "metadata": {},
   "source": [
    "**Below is how you can efficiently get output of several layers from a predefined net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed37a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def get_layer_outputs(vgg, layer_names):\n",
    "    \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
    "    outputs = [vgg.get_layer(layer[0]).output for layer in layer_names]\n",
    "\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27bcd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b48fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdf39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c1f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8ec02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c92a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c503e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40de9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2df15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a9833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634a9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f719d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-karpathy",
   "language": "python",
   "name": "venv-karpathy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
