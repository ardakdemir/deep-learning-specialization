{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e35a52",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent\n",
    "\n",
    "- Big data helped DL thrive.\n",
    "- Minibatching is an efficient way to train DL models on big data.\n",
    "\n",
    "What if you have 5 million samples in your data? It will take sooo long to take one single step in gradient descent\n",
    "\n",
    "Instead use batches of size 1k. thats all\n",
    "\n",
    "Batch gradient descent means on all 5 million examples at once.\n",
    "\n",
    "Mini-batch means on 1k examples at a time.\n",
    "\n",
    "\n",
    "1 epoch means a single pass over the whole training set. So in the above example, one epoch consists of 5k iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c80b7a",
   "metadata": {},
   "source": [
    "## Understanding Mini-batch Gradient Descent\n",
    "\n",
    "Learn more details why it works.\n",
    "\n",
    "if m=1 then it is named \"Stochastic Gradient Descent\". So we take gradient descent with one sample at a time.\n",
    "\n",
    "\n",
    "In practice, we use something in between 1 and m (two extremes).\n",
    "\n",
    "If we use size=m: Too long per iteration\n",
    "If we use size=1 (SGD): Huge disadvantage because lose speed up that would come from vectorization.\n",
    "\n",
    "So we use in-between, i.e., mini-batch:\n",
    "- Get benefits of vectorization\n",
    "- Make progress without needing to wait to process the entire training set. \n",
    "\n",
    "Mini-batch gradient descent also will never fully converge but always oscillate around the minimum region (that is because mini-batch never identical, 100% representative of the full training set). You can mitigate this by decaying the learning rate.\n",
    "\n",
    "\n",
    "### So how to choose what size is optimal for the mini-batch? \n",
    "\n",
    "Some guidelines:\n",
    "\n",
    "- If small training set: Just use batch gradient descent\n",
    "    - Around lets say 2k samples\n",
    "- Typical mini-batch sizes: 64,128,256,512 (power of 2 is good rule of thumb)\n",
    "- Make sure mini-batch fits in the CPU/GPU memory. Adjust the size appropriately.\n",
    "- This itself is a hyperparam, which is something we can tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c2aa9",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Moving Averages\n",
    "(More efficient ways of optimization then batch or mini-batch GD).\n",
    "\n",
    "Temperature in London example: moving average idea to remove the noise from each sample.\n",
    "for $\\beta=0.9$\n",
    "$$\n",
    "V(t) = 0.9 V(t-1) + 0.1 * \\Theta_t \n",
    "$$\n",
    "\n",
    "where $\\Theta_t$ is the measure temperature of that day.\n",
    "\n",
    "Doing so is equivalent to taking average over $\\dfrac{1}{1-\\beta}$ days. So for the example above, it is taking average over the last ten days (not exactly average but it is weighted average of course).\n",
    "\n",
    "\n",
    "As $\\beta$ approaches to 1 it will get smoother and smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39b365",
   "metadata": {},
   "source": [
    "## Understanding Exponentially Weighted Averages\n",
    "\n",
    "So using the basic formula above we can try to expand the equation several steps to see the recursive pattern:\n",
    "\n",
    "$$\n",
    "V_{100} = 0.1 \\Theta_{100} + 0.9 * 0.1 * \\Theta_{99} + 0.9^2 * 0.1 * \\Theta_{98} + 0.9^3 * 0.1 * \\Theta_{97} + ....\n",
    "$$\n",
    "\n",
    "Which when you think about it is an elementise product of two vectors: \n",
    "\n",
    "$$\n",
    "vector_1 = [\\Theta_{100}, \\Theta_{99},\\Theta_{98},... , \\Theta_{1}] \\\\\n",
    "vector_2 = 0.1 * [0.9^0 , 0.9^1 , 0.9^2,..., 0.9^{99} ]\n",
    "$$\n",
    "\n",
    "\n",
    "Next question: So in practice how many days does this average over?\n",
    "\n",
    "(Rough) Answer, we can use one important mathematical equation to help us have approximate answer:\n",
    "\n",
    "$$\n",
    "(1-\\epsilon)^{1/\\epsilon} = \\dfrac{1}{e}\n",
    "$$\n",
    "\n",
    "Using this equation we can say that if $\\beta=0.9$ then $(1-0.1)^{1/0.1}=\\dfrac{1}{e}$\n",
    "\n",
    "So the effect of ten days prior gets to ~ one third compared to current day. So we can say around $\\dfrac{1}{1-\\beta}$ days is averaged in the above exponentially weighted averaging.\n",
    "\n",
    "For example if $\\beta=0.98$ then we need $50$ days for the effect to get to one third.\n",
    "\n",
    "IMPORTANT: Above is just an approximation not a mathematically correct statement. \n",
    "\n",
    "**How to implement it actually?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "385eafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory efficient \n",
    "beta = 0.5\n",
    "thetas = [1,2,3,4,5,6,7,8,9,10] #imagine streaming\n",
    "V_t = 0\n",
    "# Repeat\n",
    "for theta in thetas:\n",
    "    V_t = beta * V_t + (1-beta)* theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e144f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0009765625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba36db13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac83c5",
   "metadata": {},
   "source": [
    "## Bias Correction\n",
    "Last part of the puzzle we need to build a more efficient gradient descent optimization.\n",
    "\n",
    "\n",
    "If we use the above implementation, we start with very low values since for example for the first day (since we don't have samples before it) we get 0.1 times the value of the first sample.\n",
    "\n",
    "Something like a cold start problem.\n",
    "\n",
    "\n",
    "Solution: we divide by $(1-\\beta^{t})$ to correct for small values of $t$ (beginning of the samples):\n",
    "\n",
    "So $V_t$ becomes:\n",
    "\n",
    "$$\n",
    "V_t = \\dfrac{V_t}{1-\\beta^{t}}\n",
    "$$\n",
    "\n",
    "notice that the denominator will converge to 1 since $\\beta^t$ will converge to 0 for large values of t.\n",
    "\n",
    "Some people do not bother implementing this bias correction and just wait for the gradient descent to warmup but if you want to be very accurate bias correction is calculated as above!!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3b241",
   "metadata": {},
   "source": [
    "## Gradient descent with momentum\n",
    "\n",
    "One sentence description: Compute an exponentially weighted average of your gradients.\n",
    "\n",
    "\n",
    "Momentum algorithm.\n",
    "\n",
    "On iteration t: \n",
    "- Compute dW dB on current minibatch\n",
    "- $V_{dw} = \\beta V_{dw} + (1-\\beta) dW$\n",
    "- $V_{db} = \\beta V_{db} + (1-\\beta) db$\n",
    "- Finally use $V_{dw}$ and $V_{db}$ as your gradients for update:\n",
    "\n",
    "$$\n",
    "w = w - \\alpha V_{dw}\\\\\n",
    "b = b - \\alpha V_{db}\\\\\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate.\n",
    "\n",
    "\n",
    "$\\beta=0.9$ is commonly used. And people don't even bother with the bias correction since it will correct itself in ten iterations\n",
    "\n",
    "\n",
    "**Intuition1.** Imagine an elliptic loss contour (vertically shrinked and long horizontally). At every iteration we want to take small steps along vertical axis and large steps along the horizontal axis.\n",
    "\n",
    "\n",
    "If gradient descent is oscillating up and down, using the above momentum formula will help us average out the up and down movements and at each iteration we will make a large horizontal step and a tiny vertical step. Something like course correction.\n",
    "\n",
    "\n",
    "**Intuition2.** Physics way: It is like $dW$ and $dB$ are acceleration and $V_{dW}$ and $V_{db}$ are velocity. So the gradients have influence on the final speed but can not immediately change it. If velocity was low along one direction, adding acceleration (with multiplied by $1-\\beta$) will not speed up the ball in that direction right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c0ab2",
   "metadata": {},
   "source": [
    "## RMSprop\n",
    "\n",
    "Another way to speed up gradient descent is to use RMSprop.\n",
    "\n",
    "The intuition behind it is that, if we have (in the hyperdimensional space) a large oscillation at each iteration in a direction, we want to slow it down. So we divide the gradients by the rolling average vector that we calculate (similar to momentum). This helps smooth our gradient vectors and converge faster.\n",
    "\n",
    "**How to implement:**\n",
    "For sake of simplicity lets assume we have two weights $w$ and $b$.\n",
    "\n",
    "\n",
    "- Calculate the weighted averages:\n",
    " - $S_{dw}=\\beta S_{dw} + (1-\\beta) dw^{2}$\n",
    " - $S_{db}=\\beta S_{db} + (1-\\beta) db^{2}$\n",
    "- Apply gradient descent in rms prop style:\n",
    " - $w = w - \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}$\n",
    " - $b = b - \\alpha \\dfrac{db}{\\sqrt{S_{db}}}$\n",
    " \n",
    "This means that if the oscillation along $b$ was large, we diminished this effect by dividing it with something large. This way we can use a relatively larger learning rate $\\alpha$ to speed up convergence without overshooting across some dimension.\n",
    "\n",
    "In the next step, we will actually combine RMSProp and momentum when updating the gradients. \n",
    "\n",
    "Finally, for numerical stability we actually add a small number $\\epsilon$ to the denominators so that they don't blow up if the $\\sqrt{S_{x}}$ are almost 0:\n",
    "\n",
    " - $w = w - \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}+\\epsilon}$\n",
    " - $b = b - \\alpha \\dfrac{db}{\\sqrt{S_{db}}+\\epsilon}$\n",
    "\n",
    "\n",
    "Fun fact: Geoffrey Hinton introduced RMSProp in a coursera course for the first time and made it popular actually! hehe so funny.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290fe77",
   "metadata": {},
   "source": [
    "## Adam Optimization Algorithm\n",
    "\n",
    "There have been a plethora of optimization algorithms proposed by machine learning scientists but most of them failed to generalize to other network architectures... \n",
    "\n",
    "So, the community is usually skeptic to new algorithms but RMSProp and Adam are one of those that stood the test of time!!!\n",
    "\n",
    "\n",
    "**Adam Optimization Algorithm**\n",
    "- Initialize to zero: $V_{dw}, V_{db}, S_{dw}, S_{db}$\n",
    "\n",
    "\n",
    "- Calculate momentum values $V_{dw}$ and $V_{db}$:\n",
    "\n",
    "$$\n",
    "V_{dw} = \\beta_1 V_dw+ (1-\\beta_1) dw\\\\\n",
    "V_{db} = \\beta_1 V_db+ (1-\\beta_1) db\n",
    "$$\n",
    "\n",
    "\n",
    "- Calculate RMSProp values $S_{dw}$ and $S_{db}$:\n",
    "$$\n",
    "S_{dw} = \\beta_2 S_dw+ (1-\\beta_2) dw^2\\\\\n",
    "S_{db} = \\beta_2 S_db+ (1-\\beta_2) db^2\n",
    "$$\n",
    "\n",
    "- Apply bias correction (for both Vs and Ss): \n",
    "\n",
    "$$\n",
    "V_{dw}= \\dfrac{V_{dw}}{1-\\beta_1^t}\\\\\n",
    "...\n",
    "$$\n",
    "\n",
    "\n",
    "- Then update weights by combining the two as below:\n",
    "\n",
    "$$\n",
    "w = w - \\alpha \\dfrac{V_{dw}}{\\sqrt{S_dw}+\\epsilon} \\\\ \n",
    "b = b - \\alpha \\dfrac{V_{db}}{\\sqrt{S_db}+\\epsilon} \\\\ \n",
    "$$\n",
    "\n",
    "\n",
    "where the numerator is coming from the momentum formula and denominator is coming from the RMSProp formula.\n",
    "Note $\\epsilon$ in the above equations is outside of square root!!\n",
    "\n",
    "\n",
    "Total hyperparameters: \n",
    "- $\\alpha$ needs to be tuned \n",
    "- $\\beta_1$: 0.9 ($dw$)\n",
    "- $\\beta_2$: 0.999 ($dw^2$)\n",
    "- $epsilon$: $10^{-8}$\n",
    "\n",
    "So where does the name \"ADAM\" come from?\n",
    "\n",
    "It means \"adaptive moment estimation\" since $dw$ is the first moment and $dw^2$ is the second moment of the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a110d",
   "metadata": {},
   "source": [
    "<a name='5'></a>   \n",
    "## (From Assignment) 5 - Adam\n",
    "\n",
    "Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. \n",
    "\n",
    "**How does Adam work?**\n",
    "1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). \n",
    "2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). \n",
    "3. It updates parameters in a direction based on combining information from \"1\" and \"2\".\n",
    "\n",
    "The update rule is, for $l = 1, ..., L$: \n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta_1 v_{dW^{[l]}} + (1 - \\beta_1) \\frac{\\partial \\mathcal{J} }{ \\partial W^{[l]} } \\\\\n",
    "v^{corrected}_{dW^{[l]}} = \\frac{v_{dW^{[l]}}}{1 - (\\beta_1)^t} \\\\\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "s^{corrected}_{dW^{[l]}} = \\frac{s_{dW^{[l]}}}{1 - (\\beta_2)^t} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{v^{corrected}_{dW^{[l]}}}{\\sqrt{s^{corrected}_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "where:\n",
    "- t counts the number of steps taken of Adam \n",
    "- L is the number of layers\n",
    "- $\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. \n",
    "- $\\alpha$ is the learning rate\n",
    "- $\\varepsilon$ is a very small number to avoid dividing by zero\n",
    "\n",
    "As usual, all parameters are stored in the `parameters` dictionary  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d21bcec",
   "metadata": {},
   "source": [
    "## Learning Rate Decay \n",
    "\n",
    "One thing that might speed up the learning algorithm is to use learning decay.\n",
    "\n",
    "Why? Because when you get closer and closer to the global minimum you should be making more fine-grained, small moves. If you have big steps next to the global minimum, you will keep oscillating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54587167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One implementatiopn\n",
    "current_epoch_num = 12\n",
    "decay_rate = 0.1\n",
    "initial_learning_rate = 0.1\n",
    "\n",
    "def decay(decay_rate, epoch_num,initial_learning_rate):\n",
    "    return 1/ (1+decay_rate * epoch_num) * initial_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4735664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009090909090909092"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay(0.1,100,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1404570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009900990099009901"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay(1,100,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff735016",
   "metadata": {},
   "source": [
    "Another approach is to use **exponential decay**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50043719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(decay_rate, epoch_num,initial_learning_rate):\n",
    "    \"\"\"returns the learning rate\"\"\"\n",
    "    return decay_rate**epoch_num * initial_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29fdb5",
   "metadata": {},
   "source": [
    "Another approach if you are training model that takes very long is to _Manual decay_:\n",
    "\n",
    "- Observe the loss values\n",
    "- Manually set the new learning rate\n",
    "\n",
    "\n",
    "According to Andrew, tuning the learning rate is way more higher on the list of things he would tune compared to focusing on the learning rate decay tuning. As long as you have a good learning rate, decay is apparently less important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad4986",
   "metadata": {},
   "source": [
    "## The problem of Local Optima\n",
    "\n",
    "Are local optima really problem in hyperdimensional spaces with lets say 1k dimensions???\n",
    "\n",
    "Not really! That is because a conventional local optima assumes that across all dimensions the point is the optimal value. However that is super unlikely to be the case for high dimensional spaces with 1k dimensions.\n",
    "\n",
    "What is more common is `plateaus` and `saddle points`!!\n",
    "\n",
    "- Saddle point is when a point is local minimum in terms of one dimension and local maximum in another dimension. Such a point is not an issue for gradient descent because it will get out of the saddle point by following the dimension where we had the local maxima (concave shape)\n",
    "\n",
    "- Plateaus are regions where the gradient is very low. This is real problem and might take a lot for your algorithm to get out of it.\n",
    "\n",
    "\n",
    "The fact that local optima is not a serious problem in very high dimensional space is an important lesson in machine learning. Historically we worked on 3-5 dimensions (low-dimensional spaces) and local optima was a serious problem with no clear solution. However such insights do not transfer to very high dimensional spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8c787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52ea6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defa47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581fd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449e9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82435194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9c9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114aa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509eb251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e01384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94b19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a14ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-karpathy",
   "language": "python",
   "name": "venv-karpathy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
